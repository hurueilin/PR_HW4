{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "x_test = np.load(\"x_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(550, 300)\n"
     ]
    }
   ],
   "source": [
    "# 550 data with 300 features\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# It's a binary classification problem \n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_part = x_train[:86,:]\n",
    "# print(x_train_part.shape)\n",
    "\n",
    "# y_train_part = y_train[:86]\n",
    "# print(y_train_part.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "K-fold data partition: Implement the K-fold cross-validation function. Your function should take K as an argument and return a list of lists (len(list) should equal to K), which contains K elements. Each element is a list contains two parts, the first part contains the index of all training folds, e.g. Fold 2 to Fold 5 in split 1. The second part contains the index of validation fold, e.g. Fold 1 in  split 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(x_train, y_train, k=5):\n",
    "    KFoldData = []\n",
    "    num_of_data = x_train.shape[0]\n",
    "    # Get all training data's indices and shuffle the ordering\n",
    "    data_indices = np.arange(num_of_data)\n",
    "    random.shuffle(data_indices)\n",
    "\n",
    "    if num_of_data % k == 0:\n",
    "        # Create k splits to become validation folds\n",
    "        valFolds = np.split(data_indices, k, axis=0)\n",
    "        for i in range(k):\n",
    "            currentSplit = []\n",
    "            val_fold = np.sort(valFolds[i])\n",
    "            train_fold = np.setdiff1d(data_indices, val_fold)\n",
    "            currentSplit.append(train_fold)\n",
    "            currentSplit.append(val_fold)\n",
    "            KFoldData.append(currentSplit)\n",
    "    else:\n",
    "        \"\"\" \n",
    "        When num_of_data is not divisible by K:\n",
    "        The first (n_samples % n_splits) folds have size (n_samples // n_splits + 1),\n",
    "        other folds have size (n_samples // n_splits), where n_samples is the number of samples.\n",
    "        \"\"\"\n",
    "        num_of_firstValFolds = num_of_data % k\n",
    "        num_of_otherValFolds = k - num_of_firstValFolds\n",
    "        size_of_each_firstValFold = num_of_data // k + 1\n",
    "        size_of_each_otherValFold = num_of_data // k\n",
    "        data_of_firstValFolds = data_indices[:num_of_firstValFolds*size_of_each_firstValFold]\n",
    "        data_of_otherValFolds = np.setdiff1d(data_indices, data_of_firstValFolds)\n",
    "\n",
    "        # For first parts\n",
    "        firstValFolds = np.split(data_of_firstValFolds, num_of_firstValFolds, axis=0)\n",
    "        for i in range(num_of_firstValFolds):\n",
    "            currentSplit = []\n",
    "            val_fold = np.sort(firstValFolds[i])\n",
    "            train_fold = np.setdiff1d(data_of_firstValFolds, val_fold)\n",
    "            currentSplit.append(train_fold)\n",
    "            currentSplit.append(val_fold)\n",
    "            KFoldData.append(currentSplit)\n",
    "\n",
    "        # For other parts\n",
    "        otherValFolds = np.split(data_of_otherValFolds, num_of_otherValFolds, axis=0)\n",
    "        for i in range(num_of_otherValFolds):\n",
    "            currentSplit = []\n",
    "            val_fold = np.sort(otherValFolds[i])\n",
    "            train_fold = np.setdiff1d(data_of_otherValFolds, val_fold)\n",
    "            currentSplit.append(train_fold)\n",
    "            currentSplit.append(val_fold)\n",
    "            KFoldData.append(currentSplit)\n",
    "\n",
    "    return KFoldData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_data = cross_validation(x_train, y_train, k=10)\n",
    "assert len(kfold_data) == 10 # should contain 10 fold of data\n",
    "assert len(kfold_data[0]) == 2 # each element should contain train fold and validation fold\n",
    "assert kfold_data[0][1].shape[0] == 55 # The number of data in each validation fold should equal to training data divieded by K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_kfold_data = cross_validation(x_train_part, y_train_part, k=10)\n",
    "\n",
    "# for i in range(10):\n",
    "#     print(f'Split {i}')\n",
    "#     print(test_kfold_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# X = np.arange(20)\n",
    "# kf = KFold(n_splits=5, shuffle=True)\n",
    "# kfold_data= []\n",
    "# for i, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "#     print(\"Split: %s, Training index: %s, Validation index: %s\" % (i+1, train_index, val_index))\n",
    "#     kfold_data.append([train_index, val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(kfold_data) == 5 # should contain 5 fold of data\n",
    "# assert len(kfold_data[0]) == 2 # each element should contains index of training fold and validation fold\n",
    "# assert kfold_data[0][1].shape[0] == 4 # The number of data in each validation fold should equal to training data divieded by K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Using sklearn.svm.SVC to train a classifier on the provided train set and conduct the grid search of “C”, “kernel” and “gamma” to find the best parameters by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromIdx(x_train, y_train, each_kfold_data):\n",
    "    # For training fold\n",
    "    indices = each_kfold_data[0]\n",
    "    x_train_subset = x_train[np.ix_(indices)]\n",
    "    y_train_subset = y_train[np.ix_(indices)]\n",
    "\n",
    "    # For validation fold\n",
    "    indices = each_kfold_data[1]\n",
    "    x_val = x_train[np.ix_(indices)]\n",
    "    y_val = y_train[np.ix_(indices)]\n",
    "    \n",
    "    return x_train_subset, y_train_subset, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runCrossValidation(c, gamma, kfold_data):\n",
    "    \"\"\" k-fold Cross Validation \"\"\"\n",
    "    k = len(kfold_data)\n",
    "    total_score = 0\n",
    "\n",
    "    for i in range(k):\n",
    "        x_train_subset, y_train_subset, x_val, y_val = getDataFromIdx(x_train, y_train, kfold_data[i])\n",
    "        clf = SVC(C=c, kernel='rbf', gamma=gamma)\n",
    "        clf.fit(x_train_subset, y_train_subset)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        current_accuracy = accuracy_score(y_pred, y_val)\n",
    "        print(f'(C:{c}, gamma:{gamma} -> accuracy:{current_accuracy})')\n",
    "        total_score += current_accuracy\n",
    "\n",
    "    return total_score / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(C:0.001, gamma:0.001 -> accuracy:0.6909090909090909)\n",
      "(C:0.001, gamma:0.001 -> accuracy:0.5818181818181818)\n",
      "(C:0.001, gamma:0.001 -> accuracy:0.7272727272727273)\n",
      "(C:0.001, gamma:0.001 -> accuracy:0.7454545454545455)\n",
      "(C:0.001, gamma:0.001 -> accuracy:0.5636363636363636)\n",
      "(C:0.001, gamma:0.001 -> accuracy:0.6363636363636364)\n",
      "(C:0.001, gamma:0.001 -> accuracy:0.6545454545454545)\n",
      "(C:0.001, gamma:0.001 -> accuracy:0.8)\n",
      "(C:0.001, gamma:0.001 -> accuracy:0.8)\n",
      "(C:0.001, gamma:0.001 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.001, gamma:0.001] -> 0.6890909090909091 ======\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.5818181818181818)\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.7272727272727273)\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.7454545454545455)\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.5636363636363636)\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.6363636363636364)\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.6545454545454545)\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.8)\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.8)\n",
      "(C:0.001, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.001, gamma:0.01] -> 0.6890909090909091 ======\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.5818181818181818)\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.7272727272727273)\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.7454545454545455)\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.5636363636363636)\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.6363636363636364)\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.6545454545454545)\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.8)\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.8)\n",
      "(C:0.001, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.001, gamma:0.1] -> 0.6890909090909091 ======\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.001, gamma:1.0] -> 0.6890909090909091 ======\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.001, gamma:10.0] -> 0.6890909090909091 ======\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.001, gamma:100.0] -> 0.6890909090909091 ======\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.001, gamma:1000.0] -> 0.6890909090909091 ======\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:0.001, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.001, gamma:10000.0] -> 0.6890909090909091 ======\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.6909090909090909)\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.5818181818181818)\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.7272727272727273)\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.7454545454545455)\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.5636363636363636)\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.6363636363636364)\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.6545454545454545)\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.8)\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.8)\n",
      "(C:0.01, gamma:0.001 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.01, gamma:0.001] -> 0.6890909090909091 ======\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.5818181818181818)\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.7272727272727273)\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.7454545454545455)\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.5636363636363636)\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.6363636363636364)\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.6545454545454545)\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.8)\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.8)\n",
      "(C:0.01, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.01, gamma:0.01] -> 0.6890909090909091 ======\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.5818181818181818)\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.7272727272727273)\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.7454545454545455)\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.5636363636363636)\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.6363636363636364)\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.6545454545454545)\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.8)\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.8)\n",
      "(C:0.01, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.01, gamma:0.1] -> 0.6890909090909091 ======\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.01, gamma:1.0] -> 0.6890909090909091 ======\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.01, gamma:10.0] -> 0.6890909090909091 ======\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.01, gamma:100.0] -> 0.6890909090909091 ======\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.01, gamma:1000.0] -> 0.6890909090909091 ======\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:0.01, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.01, gamma:10000.0] -> 0.6890909090909091 ======\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.6909090909090909)\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.5818181818181818)\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.7272727272727273)\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.7454545454545455)\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.5636363636363636)\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.6363636363636364)\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.6545454545454545)\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.8)\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.8)\n",
      "(C:0.1, gamma:0.001 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.1, gamma:0.001] -> 0.6890909090909091 ======\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.5818181818181818)\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.7272727272727273)\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.7454545454545455)\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.5636363636363636)\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.6363636363636364)\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.6545454545454545)\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.8)\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.8)\n",
      "(C:0.1, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.1, gamma:0.01] -> 0.6890909090909091 ======\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.5818181818181818)\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.7272727272727273)\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.7454545454545455)\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.5636363636363636)\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.6363636363636364)\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.6545454545454545)\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.8)\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.8)\n",
      "(C:0.1, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.1, gamma:0.1] -> 0.6890909090909091 ======\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.1, gamma:1.0] -> 0.6890909090909091 ======\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.1, gamma:10.0] -> 0.6890909090909091 ======\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.1, gamma:100.0] -> 0.6890909090909091 ======\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.1, gamma:1000.0] -> 0.6890909090909091 ======\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.5818181818181818)\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.7272727272727273)\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.7454545454545455)\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.5636363636363636)\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.6363636363636364)\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.6545454545454545)\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:0.1, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:0.1, gamma:10000.0] -> 0.6890909090909091 ======\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.6909090909090909)\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.5818181818181818)\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.7272727272727273)\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.7454545454545455)\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.5636363636363636)\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.6363636363636364)\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.6545454545454545)\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.8)\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.8)\n",
      "(C:1.0, gamma:0.001 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1.0, gamma:0.001] -> 0.6890909090909091 ======\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.5818181818181818)\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.7272727272727273)\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.7454545454545455)\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.5636363636363636)\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.6363636363636364)\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.6545454545454545)\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.8)\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.8)\n",
      "(C:1.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1.0, gamma:0.01] -> 0.6890909090909091 ======\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.5818181818181818)\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.7272727272727273)\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.7454545454545455)\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.5636363636363636)\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.6363636363636364)\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.6545454545454545)\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:1.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1.0, gamma:0.1] -> 0.6890909090909091 ======\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.5818181818181818)\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.7272727272727273)\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.7454545454545455)\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.5636363636363636)\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.6363636363636364)\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.6545454545454545)\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1.0, gamma:1.0] -> 0.6890909090909091 ======\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.5818181818181818)\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.7272727272727273)\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.7454545454545455)\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.5636363636363636)\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.6363636363636364)\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.6545454545454545)\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1.0, gamma:10.0] -> 0.6890909090909091 ======\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.5818181818181818)\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.7272727272727273)\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.7454545454545455)\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.5636363636363636)\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.6363636363636364)\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.6545454545454545)\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1.0, gamma:100.0] -> 0.6890909090909091 ======\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.5818181818181818)\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.7272727272727273)\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.7454545454545455)\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.5636363636363636)\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.6363636363636364)\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.6545454545454545)\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1.0, gamma:1000.0] -> 0.6890909090909091 ======\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.5818181818181818)\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.7272727272727273)\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.7454545454545455)\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.5636363636363636)\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.6363636363636364)\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.6545454545454545)\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:1.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1.0, gamma:10000.0] -> 0.6890909090909091 ======\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.9272727272727272)\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.8363636363636363)\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.8909090909090909)\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.9454545454545454)\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.8181818181818182)\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.8909090909090909)\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.8545454545454545)\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.9636363636363636)\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.9090909090909091)\n",
      "(C:10.0, gamma:0.001 -> accuracy:0.8727272727272727)\n",
      "====== avg score of hyp[C:10.0, gamma:0.001] -> 0.8909090909090909 ======\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.5818181818181818)\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.7272727272727273)\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.7454545454545455)\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.5636363636363636)\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.6363636363636364)\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.6545454545454545)\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.8)\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.8181818181818182)\n",
      "(C:10.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10.0, gamma:0.01] -> 0.6909090909090908 ======\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.5818181818181818)\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.7272727272727273)\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.7454545454545455)\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.5636363636363636)\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.6363636363636364)\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.6545454545454545)\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:10.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10.0, gamma:0.1] -> 0.6890909090909091 ======\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.5818181818181818)\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.7272727272727273)\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.7454545454545455)\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.5636363636363636)\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.6363636363636364)\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.6545454545454545)\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10.0, gamma:1.0] -> 0.6890909090909091 ======\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.5818181818181818)\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.7272727272727273)\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.7454545454545455)\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.5636363636363636)\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.6363636363636364)\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.6545454545454545)\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10.0, gamma:10.0] -> 0.6890909090909091 ======\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.5818181818181818)\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.7272727272727273)\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.7454545454545455)\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.5636363636363636)\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.6363636363636364)\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.6545454545454545)\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10.0, gamma:100.0] -> 0.6890909090909091 ======\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.5818181818181818)\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.7272727272727273)\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.7454545454545455)\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.5636363636363636)\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.6363636363636364)\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.6545454545454545)\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10.0, gamma:1000.0] -> 0.6890909090909091 ======\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.5818181818181818)\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.7272727272727273)\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.7454545454545455)\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.5636363636363636)\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.6363636363636364)\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.6545454545454545)\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:10.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10.0, gamma:10000.0] -> 0.6890909090909091 ======\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.9272727272727272)\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.8363636363636363)\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.8909090909090909)\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.9454545454545454)\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.8181818181818182)\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.8909090909090909)\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.8545454545454545)\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.9636363636363636)\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.9090909090909091)\n",
      "(C:100.0, gamma:0.001 -> accuracy:0.8727272727272727)\n",
      "====== avg score of hyp[C:100.0, gamma:0.001] -> 0.8909090909090909 ======\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.5818181818181818)\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.7272727272727273)\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.7454545454545455)\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.5636363636363636)\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.6363636363636364)\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.6545454545454545)\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.8)\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.8181818181818182)\n",
      "(C:100.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:100.0, gamma:0.01] -> 0.6909090909090908 ======\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.5818181818181818)\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.7272727272727273)\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.7454545454545455)\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.5636363636363636)\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.6363636363636364)\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.6545454545454545)\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:100.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:100.0, gamma:0.1] -> 0.6890909090909091 ======\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.5818181818181818)\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.7272727272727273)\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.7454545454545455)\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.5636363636363636)\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.6363636363636364)\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.6545454545454545)\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:100.0, gamma:1.0] -> 0.6890909090909091 ======\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.5818181818181818)\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.7272727272727273)\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.7454545454545455)\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.5636363636363636)\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.6363636363636364)\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.6545454545454545)\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:100.0, gamma:10.0] -> 0.6890909090909091 ======\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.5818181818181818)\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.7272727272727273)\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.7454545454545455)\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.5636363636363636)\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.6363636363636364)\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.6545454545454545)\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:100.0, gamma:100.0] -> 0.6890909090909091 ======\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.5818181818181818)\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.7272727272727273)\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.7454545454545455)\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.5636363636363636)\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.6363636363636364)\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.6545454545454545)\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:100.0, gamma:1000.0] -> 0.6890909090909091 ======\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.5818181818181818)\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.7272727272727273)\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.7454545454545455)\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.5636363636363636)\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.6363636363636364)\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.6545454545454545)\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:100.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:100.0, gamma:10000.0] -> 0.6890909090909091 ======\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.9272727272727272)\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.8363636363636363)\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.8909090909090909)\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.9454545454545454)\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.8181818181818182)\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.8909090909090909)\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.8545454545454545)\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.9636363636363636)\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.9090909090909091)\n",
      "(C:1000.0, gamma:0.001 -> accuracy:0.8727272727272727)\n",
      "====== avg score of hyp[C:1000.0, gamma:0.001] -> 0.8909090909090909 ======\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.5818181818181818)\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.7272727272727273)\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.7454545454545455)\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.5636363636363636)\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.6363636363636364)\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.6545454545454545)\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.8181818181818182)\n",
      "(C:1000.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1000.0, gamma:0.01] -> 0.6909090909090908 ======\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.5818181818181818)\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.7272727272727273)\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.7454545454545455)\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.5636363636363636)\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.6363636363636364)\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.6545454545454545)\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1000.0, gamma:0.1] -> 0.6890909090909091 ======\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.5818181818181818)\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.7272727272727273)\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.7454545454545455)\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.5636363636363636)\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.6363636363636364)\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.6545454545454545)\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1000.0, gamma:1.0] -> 0.6890909090909091 ======\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.5818181818181818)\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.7272727272727273)\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.7454545454545455)\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.5636363636363636)\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.6363636363636364)\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.6545454545454545)\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1000.0, gamma:10.0] -> 0.6890909090909091 ======\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.5818181818181818)\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.7272727272727273)\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.7454545454545455)\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.5636363636363636)\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.6363636363636364)\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.6545454545454545)\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1000.0, gamma:100.0] -> 0.6890909090909091 ======\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.5818181818181818)\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.7272727272727273)\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.7454545454545455)\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.5636363636363636)\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.6363636363636364)\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.6545454545454545)\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1000.0, gamma:1000.0] -> 0.6890909090909091 ======\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.5818181818181818)\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.7272727272727273)\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.7454545454545455)\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.5636363636363636)\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.6363636363636364)\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.6545454545454545)\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:1000.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:1000.0, gamma:10000.0] -> 0.6890909090909091 ======\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.9272727272727272)\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.8363636363636363)\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.8909090909090909)\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.9454545454545454)\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.8181818181818182)\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.8909090909090909)\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.8545454545454545)\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.9636363636363636)\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.9090909090909091)\n",
      "(C:10000.0, gamma:0.001 -> accuracy:0.8727272727272727)\n",
      "====== avg score of hyp[C:10000.0, gamma:0.001] -> 0.8909090909090909 ======\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.5818181818181818)\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.7272727272727273)\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.7454545454545455)\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.5636363636363636)\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.6363636363636364)\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.6545454545454545)\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.8181818181818182)\n",
      "(C:10000.0, gamma:0.01 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10000.0, gamma:0.01] -> 0.6909090909090908 ======\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.5818181818181818)\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.7272727272727273)\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.7454545454545455)\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.5636363636363636)\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.6363636363636364)\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.6545454545454545)\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:0.1 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10000.0, gamma:0.1] -> 0.6890909090909091 ======\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.5818181818181818)\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.7272727272727273)\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.7454545454545455)\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.5636363636363636)\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.6363636363636364)\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.6545454545454545)\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:1.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10000.0, gamma:1.0] -> 0.6890909090909091 ======\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.5818181818181818)\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.7272727272727273)\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.7454545454545455)\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.5636363636363636)\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.6363636363636364)\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.6545454545454545)\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:10.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10000.0, gamma:10.0] -> 0.6890909090909091 ======\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.5818181818181818)\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.7272727272727273)\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.7454545454545455)\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.5636363636363636)\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.6363636363636364)\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.6545454545454545)\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:100.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10000.0, gamma:100.0] -> 0.6890909090909091 ======\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.5818181818181818)\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.7272727272727273)\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.7454545454545455)\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.5636363636363636)\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.6363636363636364)\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.6545454545454545)\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:1000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10000.0, gamma:1000.0] -> 0.6890909090909091 ======\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.5818181818181818)\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.7272727272727273)\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.7454545454545455)\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.5636363636363636)\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.6363636363636364)\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.6545454545454545)\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.8)\n",
      "(C:10000.0, gamma:10000.0 -> accuracy:0.6909090909090909)\n",
      "====== avg score of hyp[C:10000.0, gamma:10000.0] -> 0.6890909090909091 ======\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Grid search to find the best C and gamma \"\"\"\n",
    "C_list = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "Gamma_list = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "best_accuracy = 0.0\n",
    "best_C, best_gamma = None, None\n",
    "\n",
    "for c in C_list:\n",
    "    for gamma in Gamma_list:\n",
    "        # For current hyperparameter setting, run cross validation and get the average score\n",
    "        average_score = runCrossValidation(c, gamma, kfold_data)\n",
    "        print(f'====== avg score of hyp[C:{c}, gamma:{gamma}] -> {average_score} ======')\n",
    "\n",
    "        if(best_accuracy < average_score):\n",
    "            best_accuracy =  average_score\n",
    "            best_C = c\n",
    "            best_gamma = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8909090909090909\n10.0\n0.001\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)\n",
    "print(best_C)\n",
    "print(best_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_parameters:\nC:10.0, gamma:0.001\n"
     ]
    }
   ],
   "source": [
    "print('best_parameters:')\n",
    "print(f'C:{best_C}, gamma:{best_gamma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Plot the grid search results of your SVM. The x, y represents the hyperparameters of “gamma” and “C”, respectively. And the color represents the average score of validation folds\n",
    "You reults should be look like this reference image below ![image](https://miro.medium.com/max/1296/1*wGWTup9r4cVytB5MOnsjdQ.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Train your SVM model by the best parameters you found from question 2 on the whole training set and evaluate the performance on the test set. **You accuracy should over 0.85**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=10.0, gamma=0.001)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Do the SVM on whole training set based on the best hyperparameters we just found\n",
    "best_model = SVC(C=best_C, kernel='rbf', gamma=best_gamma)\n",
    "best_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score:  0.8958333333333334\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(x_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Compare the performance of the model you have implemented in HW1 with the SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../HW1/train_data.csv\")\n",
    "x_train = train_df['x_train'].to_numpy().reshape(-1,1)\n",
    "y_train = train_df['y_train'].to_numpy().reshape(-1,1)\n",
    "\n",
    "test_df = pd.read_csv(\"../HW1/test_data.csv\")\n",
    "x_test = test_df['x_test'].to_numpy().reshape(-1,1)\n",
    "y_test = test_df['y_test'].to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square error of Linear regression: \n",
      "Square error of SVM regresssion model: \n"
     ]
    }
   ],
   "source": [
    "print(\"Square error of Linear regression: \")\n",
    "print(\"Square error of SVM regresssion model: \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python387jvsc74a57bd073971114097a847891760271ed9e4a82bf53c842c05d942db8283790dc357343",
   "display_name": "Python 3.8.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}